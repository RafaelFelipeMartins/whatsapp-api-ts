import dotenv from "dotenv";
import { Client, LocalAuth, Message, Chat } from "whatsapp-web.js";
import qrcode from "qrcode-terminal";
import fs from "fs";
import path from "path";
import OpenAI from "openai";

dotenv.config();

const allowedNumbers = [
  '554197309009@c.us',
  '554184611703@c.us',
  '554197399754@c.us'
];

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

const client = new Client({
  authStrategy: new LocalAuth(),
});

// üó£Ô∏è Mensagens padr√£o
const introMessage = `
üëã Ol√°! Eu sou o bot do *EcoLendas* ‚ôªÔ∏è  
Eu te ajudo a mapear locais com descarte incorreto de lixo.  
Envie uma *foto* de um local polu√≠do para come√ßarmos!
`;

const confirmationQuestion = `Essa descri√ß√£o est√° correta?\n\nResponda com *sim* ou *n√£o*.`;

const locationRequest = `üìç Agora, por favor, compartilhe a localiza√ß√£o exata ou envie o endere√ßo do local da foto.`;

const thankYouMessage = `
‚úÖ Obrigado! Sua contribui√ß√£o ajuda a combater a polui√ß√£o e proteger o meio ambiente üå±  
Tenha um √≥timo dia!
`;

// üì∏ Fun√ß√£o de an√°lise da imagem
async function analyzeImage(imagePath: string): Promise<string> {
  const base64Image = fs.readFileSync(imagePath, "base64");

  const response = await openai.responses.create({
    model: "gpt-4.1-mini",
    input: [
      {
        role: "system",
        content: `
          Voc√™ √© um assistente que analisa imagens para detectar lixo.
          Voc√™ deve descrever brevemente os tipos de lixo presentes, marcas de produtos identificadas e o cen√°rio.
          Se a imagem parecer falsa, responda apenas "Imagem n√£o aparenta ser verdadeira".
          Se n√£o houver lixo, responda "Lixo n√£o encontrado".
        `,
      },
      {
        role: "user",
        content: [
          {
            type: "input_image",
            image_url: `data:image/jpeg;base64,${base64Image}`,
            detail: "high"
          },
        ],
      },
    ],
  });

  const textOutput = response.output
    .filter((item) => item.type === "message")
    .flatMap((item: any) => item.content || [])
    .find((c: any) => c.type === "output_text");

  if (!textOutput) {
    throw new Error("No text output found in OpenAI response");
  }

  return textOutput.text.trim();
}

// üîÑ Estado de conversa tempor√°rio
interface UserState {
  stage: "intro" | "image" | "confirm" | "location" | "done";
  imagePath?: string;
  description?: string;
}

const userState = new Map<string, UserState>();

// üöÄ Inicializa√ß√£o
client.on("qr", (qr) => {
  console.log("üì≤ Escaneie o QR code abaixo para conectar:");
  qrcode.generate(qr, { small: true });
});

client.on("ready", () => {
  console.log("‚úÖ Bot conectado e pronto!");
});

client.on("message", async (msg: Message) => {
  const chat: Chat = await msg.getChat();
  const from = msg.from;

  if (chat.isGroup || !allowedNumbers.includes(from)) return;

  const state = userState.get(from) || { stage: "intro" };
  let response = "";

  switch (state.stage) {
    case "intro":
      response = introMessage;
      state.stage = "image";
      break;

    case "image":
      if (msg.type === "image") {
        const media = await msg.downloadMedia();
        if (!media?.data) {
          response = "‚ö†Ô∏è N√£o consegui baixar a imagem, envie novamente.";
          break;
        }

        const dir = "./uploads";
        if (!fs.existsSync(dir)) fs.mkdirSync(dir);
        const imagePath = path.join(dir, `report_${Date.now()}.jpg`);
        fs.writeFileSync(imagePath, media.data, { encoding: "base64" });

        const analysis = await analyzeImage(imagePath);

        if (analysis.includes("n√£o aparenta ser verdadeira")) {
          response = "‚ö†Ô∏è Imagem n√£o parece real. Tente enviar outra.";
        } else if (analysis.includes("Lixo n√£o encontrado")) {
          response = "üßπ N√£o identifiquei lixo na imagem. Tente outra foto, por favor.";
        } else {
          state.stage = "confirm";
          state.imagePath = imagePath;
          state.description = analysis;
          response = `üì∏ An√°lise da imagem:\n\n${analysis}\n\n${confirmationQuestion}`;
        }
      } else {
        response = "üì∏ Por favor, envie uma *imagem* do local com lixo.";
      }
      break;

    case "confirm":
      if (msg.body.toLowerCase().includes("sim")) {
        state.stage = "location";
        response = locationRequest;
      } else if (msg.body.toLowerCase().includes("n√£o")) {
        response = "üòÖ Tudo bem! Envie novamente a *foto correta*.";
        state.stage = "image";
      } else {
        response = "Por favor, responda apenas com *sim* ou *n√£o*.";
      }
      break;

    case "location":
      if (msg.type === "location" || msg.type === "chat") {
        const locationData =
          msg.type === "location"
            ? `Latitude: ${msg.location?.latitude}, Longitude: ${msg.location?.longitude}`
            : msg.body.trim();

        const reportDir = "./reports";
        if (!fs.existsSync(reportDir)) fs.mkdirSync(reportDir);

        const reportContent = `
Descri√ß√£o: ${state.description}
Localiza√ß√£o: ${locationData}
Imagem: ${state.imagePath}
Data: ${new Date().toLocaleString()}
        `;

        fs.writeFileSync(
          path.join(reportDir, `report_${Date.now()}.txt`),
          reportContent
        );

        response = thankYouMessage;
        state.stage = "done";
      } else {
        response = "üìç Envie a localiza√ß√£o ou um endere√ßo v√°lido.";
      }
      break;

    case "done":
      response = "üåç Obrigado novamente! Caso queira fazer outro envio, reinicie a conversa.";
      break;
  }

  userState.set(from, state);

  if (response) {
    await msg.reply(response);
  }
});

client.initialize();
